import cv2
import os
import json
from PIL import Image
import numpy as np

DATASET_DIR = "faces_db"
METADATA_FILE = os.path.join(DATASET_DIR, "metadata.json")

def create_dataset():
    """Thu th·∫≠p ·∫£nh khu√¥n m·∫∑t v√† th√¥ng tin sinh vi√™n"""
    
    if not os.path.exists(DATASET_DIR):
        os.makedirs(DATASET_DIR)
    
    # Load metadata c≈© (n·∫øu c√≥)
    metadata = {"uniforms": {}}
    if os.path.exists(METADATA_FILE):
        with open(METADATA_FILE, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    
    cap = cv2.VideoCapture(0)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    
    print("\n=== TRAIN KHU√îN M·∫∂T V√Ä TH√îNG TIN SINH VI√äN ===\n")
    
    while True:
        name = input("Nh·∫≠p t√™n sinh vi√™n (ho·∫∑c 'q' ƒë·ªÉ tho√°t): ").strip()
        if name.lower() == 'q':
            break
        
        if not name:
            print("‚ö† T√™n kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!")
            continue
        
        # Nh·∫≠p th√¥ng tin ƒë·ªìng ph·ª•c
        print("\nM√†u ƒë·ªìng ph·ª•c:")
        print("1. Tr·∫Øng (white)")
        print("2. Xanh navy (blue)")
        uniform_choice = input("Ch·ªçn (1/2): ").strip()
        uniform_color = "white" if uniform_choice == "1" else "blue"
        
        metadata["uniforms"][name] = uniform_color
        
        # T·∫°o th∆∞ m·ª•c cho sinh vi√™n
        person_dir = os.path.join(DATASET_DIR, name)
        if not os.path.exists(person_dir):
            os.makedirs(person_dir)
        
        print(f"\nüì∏ Thu th·∫≠p ·∫£nh cho {name}...")
        print("H∆∞·ªõng d·∫´n: Nh√¨n th·∫≥ng v√†o camera, thay ƒë·ªïi g√≥c ƒë·ªô nh·∫π")
        print("Nh·∫•n SPACE ƒë·ªÉ ch·ª•p (30 ·∫£nh) | ESC ƒë·ªÉ b·ªè qua\n")
        
        count = 0
        target = 30
        
        while count < target:
            ret, frame = cap.read()
            if not ret:
                break
            
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(100, 100))
            
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            
            progress = f"{count}/{target}"
            cv2.putText(frame, progress, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, name, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            cv2.imshow("Train Faces", frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == 32:  # SPACE
                if len(faces) > 0:
                    x, y, w, h = faces[0]
                    face_img = gray[y:y+h, x:x+w]
                    img_path = os.path.join(person_dir, f"{name}_{count}.jpg")
                    cv2.imwrite(img_path, face_img)
                    count += 1
                    print(f"‚úì ƒê√£ l∆∞u {count}/{target}")
                else:
                    print("‚ö† Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t!")
            
            elif key == 27:  # ESC
                print("‚ö† ƒê√£ b·ªè qua")
                break
        
        print(f"\n‚úì Ho√†n t·∫•t thu th·∫≠p cho {name}: {count} ·∫£nh\n")
    
    # L∆∞u metadata
    with open(METADATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    cap.release()
    cv2.destroyAllWindows()
    
    print("\n‚úì ƒê√£ l∆∞u to√†n b·ªô d·ªØ li·ªáu!")
    print(f"‚úì Metadata: {METADATA_FILE}")
    print(f"‚úì T·ªïng s·ªë sinh vi√™n: {len(metadata['uniforms'])}\n")

def view_dataset():
    """Xem danh s√°ch sinh vi√™n ƒë√£ train"""
    if not os.path.exists(METADATA_FILE):
        print("‚ö† Ch∆∞a c√≥ d·ªØ li·ªáu!")
        return
    
    with open(METADATA_FILE, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    print("\n=== DANH S√ÅCH SINH VI√äN ƒê√É TRAIN ===\n")
    for name, uniform in metadata['uniforms'].items():
        person_dir = os.path.join(DATASET_DIR, name)
        img_count = len(os.listdir(person_dir)) if os.path.exists(person_dir) else 0
        print(f"‚Ä¢ {name} - ƒê·ªìng ph·ª•c: {uniform} - S·ªë ·∫£nh: {img_count}")
    print()

def delete_person():
    """X√≥a m·ªôt sinh vi√™n kh·ªèi dataset"""
    view_dataset()
    name = input("\nNh·∫≠p t√™n sinh vi√™n c·∫ßn x√≥a: ").strip()
    
    if not name:
        return
    
    person_dir = os.path.join(DATASET_DIR, name)
    if os.path.exists(person_dir):
        import shutil
        shutil.rmtree(person_dir)
        print(f"‚úì ƒê√£ x√≥a th∆∞ m·ª•c {name}")
    
    # X√≥a kh·ªèi metadata
    if os.path.exists(METADATA_FILE):
        with open(METADATA_FILE, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        if name in metadata['uniforms']:
            del metadata['uniforms'][name]
            with open(METADATA_FILE, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            print(f"‚úì ƒê√£ x√≥a {name} kh·ªèi metadata")

if __name__ == "__main__":
    while True:
        print("\n=== QU·∫¢N L√ù DATASET SINH VI√äN ===")
        print("1. Train khu√¥n m·∫∑t m·ªõi")
        print("2. Xem danh s√°ch")
        print("3. X√≥a sinh vi√™n")
        print("4. Tho√°t")
        
        choice = input("\nCh·ªçn: ").strip()
        
        if choice == "1":
            create_dataset()
        elif choice == "2":
            view_dataset()
        elif choice == "3":
            delete_person()
        elif choice == "4":
            break
        else:
            print("‚ö† L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
